{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sb\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Networks: structure, evolution & processes\n",
    "**Internet Analytics - Lab 2**\n",
    "\n",
    "---\n",
    "\n",
    "**Group:** *Your group letter.*\n",
    "\n",
    "**Names:**\n",
    "\n",
    "* *Name 1*\n",
    "* *Name 2*\n",
    "* *Name 3*\n",
    "\n",
    "---\n",
    "\n",
    "#### Instructions\n",
    "\n",
    "*This is a template for part 4 of the lab. Clearly write your answers, comments and interpretations in Markodown cells. Don't forget that you can add $\\LaTeX$ equations in these cells. Feel free to add or remove any cell.*\n",
    "\n",
    "*Please properly comment your code. Code readability will be considered for grading. To avoid long cells of codes in the notebook, you can also embed long python functions and classes in a separate module. Donâ€™t forget to hand in your module if that is the case. In multiple exercises, you are required to come up with your own method to solve various problems. Be creative and clearly motivate and explain your methods. Creativity and clarity will be considered for grading.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 2.4 PageRank\n",
    "\n",
    "### 2.4.1 Random Surfer Model\n",
    "\n",
    "#### Exercise 2.12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from random import choice\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from networkx.readwrite import edgelist\n",
    "G1 = nx.read_adjlist('../data/components.graph', create_using=nx.DiGraph())\n",
    "G2 = nx.read_adjlist('../data/absorbing.graph', create_using=nx.DiGraph())\n",
    "W = nx.read_adjlist('../data/wikipedia.graph', create_using=nx.DiGraph())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def random_surfer(G, hops=1000):\n",
    "    visits = defaultdict(int)\n",
    "    \n",
    "    node = choice(G.nodes())\n",
    "    for _ in range(hops):\n",
    "        visits[node] += 1\n",
    "        \n",
    "        try:\n",
    "            node = choice(G.neighbors(node))\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "    for key in visits :\n",
    "        print(\"{}: {}\".format(key, visits[key]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the components graph, we see that we do not reach the whole network, because there are un-connected components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4: 284\n",
      "5: 150\n",
      "6: 283\n",
      "7: 283\n"
     ]
    }
   ],
   "source": [
    "random_surfer(G1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the absorbing graph, we get stuck in the node without any out-edges, which therefore gets all the visits.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1: 1000\n"
     ]
    }
   ],
   "source": [
    "random_surfer(G2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 2.13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from random import random\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "DAMPING_FACTOR = 0.15\n",
    "\n",
    "def page_rank(G, hops=1000):\n",
    "    visits = defaultdict(int)\n",
    "    \n",
    "    node = choice(G.nodes())\n",
    "    for _ in range(hops):\n",
    "        visits[node] += 1\n",
    "        \n",
    "        if random() > DAMPING_FACTOR:\n",
    "            neighbors = G.neighbors(node)\n",
    "            if neighbors:\n",
    "                node = choice(G.neighbors(node))\n",
    "            else:\n",
    "                node = choice(G.nodes())\n",
    "        else:\n",
    "            node = choice(G.nodes())\n",
    "        \n",
    "    for key in visits :\n",
    "        print(\"{}: {}\".format(key, visits[key]))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: 173\n",
      "1: 166\n",
      "3: 86\n",
      "2: 173\n",
      "6: 115\n",
      "7: 111\n",
      "4: 116\n",
      "5: 60\n"
     ]
    }
   ],
   "source": [
    "page_rank(G1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3: 217\n",
      "0: 168\n",
      "4: 151\n",
      "1: 315\n",
      "2: 149\n"
     ]
    }
   ],
   "source": [
    "page_rank(G2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These results seems to make sence. Nodes with few in-edges get lower score, and if a node has an in-edge only from nodes with many out-edges, it gets 'penalized' for this."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### 2.4.2 Power Iteration Method\n",
    "\n",
    "#### Exercise 2.14: Power Iteration method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "titles = pd.DataFrame.from_csv('../data/wikipedia_titles.tsv', sep='\\t', )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def page_rank_power(G, hops=1000, delta_lim=1e-3):\n",
    "    N = len(G.nodes())\n",
    "    pi = np.array([1/N]*N)\n",
    "    \n",
    "    H = np.zeros((N, N))\n",
    "    for u, v in G.edges_iter():\n",
    "        o_u = len(G.neighbors(u))\n",
    "        H[int(u), int(v)] = 1/o_u\n",
    "        \n",
    "    dangeling = lambda x: len(G.neighbors(x)) == 0\n",
    "    w = [1 if dangeling(x) else 0 for x in G.nodes()]\n",
    "    \n",
    "    H_hat = H + (w * np.identity(N).T) / N\n",
    "    \n",
    "    G = (1 - DAMPING_FACTOR) * H_hat + DAMPING_FACTOR * np.ones((N, N)) / N\n",
    "    \n",
    "    for k in range(hops):\n",
    "        _pi = np.dot(pi, G)\n",
    "        \n",
    "        if np.sum(np.abs(pi - _pi)) < delta_lim:\n",
    "            print(\"Convergence after {} steps...\".format(k))\n",
    "            break\n",
    "        if k + 1 == hops:\n",
    "            print(\"Reached maximum number of steps: {}...\".format(k))\n",
    "            \n",
    "        pi = _pi\n",
    "        \n",
    "    return pi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Convergence after 8 steps...\n"
     ]
    }
   ],
   "source": [
    "wiki_rank = page_rank_power(W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ranks = np.argsort(wiki_rank)[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "docs = [titles.ix[r]['page_title'] for r in ranks[:10]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1: United States\n",
      "2: United Kingdom\n",
      "3: France\n",
      "4: Europe\n",
      "5: Germany\n",
      "6: England\n",
      "7: World War II\n",
      "8: Latin\n",
      "9: India\n",
      "10: English language\n"
     ]
    }
   ],
   "source": [
    "Print top 10 rankings:\n",
    "for i, title in enumerate(docs):\n",
    "    print(\"{}: {}\".format(i+1, title))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### 2.4.3 Gaming the system *(Bonus)*\n",
    "\n",
    "#### Exercise 2.15 *(Bonus)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
